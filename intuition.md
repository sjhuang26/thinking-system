> Quotes are "side thoughts" in my multi-document writing workflow.

I'm really having trouble expressing the main intuition. When you know there's something new, you really feel it, but then when you write it down, even though it only takes a few main metaphors, it's hard!

The SMART training (Relational Frame Theory) says that Multiple Exemplar Training is a scientifically proven way to increase IQ through mastering "arbitrary applicable derived relations." I agree with the goal of training general relational response, I argue that  Multiple Exemplar Training is misapplied rote learning. Radical behaviorism feels like a neat and tidy construct where stimulus classes, as nice "tokens" of thought, are "pushed around" by the brain and yield various behaviors, but someone critical of rote learning would say that efficiency comes from proficiency in metaphor. From this general notion, I recommend a new application of Relational Frame Theory that is based on a journey of conceptualistic development.

At a philosophical level, I establish a dichotomy where the CPU is about Reward and Punishment (operant reinforcement, rote learning) while the GPU is about Rationality (simulating the future from the episodic past and the episodic present, cognitive map, creative intuition, maps of language rhetoric, mental models). Arbitrarily applicable derived relations are characterized as superficially in the CPU and essentially in the GPU.

A movement from CPU to GPU is essential to avoiding existential crisis. In the theraputic context, this is what the use of abstract ACT defusion techniques does.

The GPU creates a local maxima of rationality each moment: consistently "Correct" behavior.

Explanation of GPU.

> The process of instilling first principles is causually grounded in the self-organization of the map over years of sensory cues flowing in and behavior flowing out. The first principles combinatorially generalize such that first principles have other first principles themselves.

Explanation of CPU.

> The CPU is a mechanism of operant reinforcement that creates "bubblesÂ¨ in the GPU, developmentally leading to the emergence of a "token language" (sounds representing tokens). However, once the CPU-driven stage completes, if the CPU's emergent language of tokens dominates further, it is existentially unfulfilling.

Is it the CPU or the GPU that drives IQ?

> In many cases, the GPU can let go of the helping hand of the CPU. The GPU can self-organize; for example, in a logic puzzle, the bubble corresponding to "A == B" can be expanded to cause the proliferation of "NOT (A =/= B)" which may subsequently bubble into awareness. This parallels the conventional Relational Frame Theory explanation.

The GPU is hypothesized to have the following three characteristics. This is the result of guesswork.

1. SAME-DIFF teaches attention.
2. MORE-LESS teaches snowballing.
3. HIERARCHY teaches painting.

> exclusionary attention as an interaction between every combinatorial pair of details

> exclusionary attention as an interaction between every combinatorial pair of tokens

> exclusionary attention as paying attention to This Thing while being precommitted to One Other Thing (temporal ping-pong)

> Formalism 1: visual comparison of density. Hazy visualization, clear visualization, actually visually seeing the object in the present moment. Formalism 2: snowballing from 0 to 01 to 012, item #N in fact contains all items from 1 to N. Formalism 3: remembering the answer (2) to a quiz question (1). Formalism 4: use of NULL as a generic "zero item" that all "items" originate from.

> Neuron networks are hierarchies that (1) are encapsulated by a token (2) can be painted with a color (RED-GREEN) (3) encode variegated details in various densities of detail. As a result, there is the token-details relationship. One token encapsulates many details. Details can be shared by tokens.

> Density is acted upon by the Ebbinghaus principles of forgetting. The present sensory stream-of-consciousness is an asymptote of virtually infinite density, conventional episodic memory is worse, and declarative memory is especially low. NOTE: In some training contexts (e.g., spatial-visual), it is easy to absorb density; the speed that the individual hierarchically unpacks big details into little details (many of which are memorized and retained) is astoundingly fast compared to the declarative memory schemas.

> The input of the present sensory data is equivalent to encoding an extremely strong episodic memory that immediately begins to fade by Ebbinghaus.

Here are the two steps for the CPU to relinquish its cognitive responsibilities.

1. imagine both correct and incorrect
2. learn a ton of metaphors

> visualize imagining correctly and then visualize imagining incorrectly. At this point, behavior flows unhindered from the Correct-Incorrect binary (a local maxima of rationality in the moment) that the cognitive map directly maps into. Principle of surprise >> on how surprising the difference between present and memory is, you should judge the quality of mental recall (affects all RFT relations earlier described)

> Educational constructs were learned through rote, requiring you to re-learn a bunch of stuff. For instance, the use of memorizing a "NOT" sign for the NOT relation. A "LESS" sign for the LESS relation. etc. metaphor-ize the relations and other rote understandings; create a productive standardized format of data exchange (Serial Data Code Full Text); base everything off of that home base

> same-different (e.g., hot vs. cold), more-less (e.g., small snowball, big snowball), hierarchy (e.g., zoom in / zoom out)

SAME-DIFF: Given two tokens, A and B, alter which object you are paying attention to. Do this in a rapid temporal ping-pong.

> CPU executive control and CPU attention >> GPU attention. The GPU attention is done by threatening yourself to pay attention properly using a "10% chance" of a random quiz.

> This might be the origin of visualization or the "mind's eye": ping pong between Present and Synthesis of Prior Episodic Memories (including the episodic memory of the present).

MORE-LESS: Create a sequence of densities.

> At any point in time, there may exist many representations of the same physical object with wildly varying densities.

> Present = high. Far past = low. Question AND answer = high. Question = low. Realism = high. Cartoony appearance that is more encodable or memorable = low. Words = really low. Also practice numbering items in a memory palace journey. Do the Correct-Incorrect exercises over the densities to suppress the CPU's operants.

> The GPU can do deep-mapping as a density-preserving operation. A strong image (e.g., the Present vision) can be deep-mapped into a strong image of a visualizations (e.g., coloring objects Red/Green/Gray) which can be also encoded in episodic memory. Deep mapping is an important marker of the upper end of the density scale.

HIERARCHY: I believe the painting of details in hierarchies is best learned by the context of ping-pong: RED hierarchy vs. GREEN hierarchy.

> String together arbitrary detail within A to arbitrary detail within B.
